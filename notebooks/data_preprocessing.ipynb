{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Notebook to load raw CSVs, clean and merge them, and save a single processed file `data/processed_data.csv`.\n",
    "\n",
    "Notes:\n",
    "- Looks for raw files in `data/rawdata/`, `data/raw/`, `rawdata/`, or `archive/`.\n",
    "- Uses `src.preprocessing` utilities (`clean_numeric_columns`, `parse_dates`, `save_processed`) for consistent cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:44:18.419976Z",
     "iopub.status.busy": "2026-01-08T04:44:18.419816Z",
     "iopub.status.idle": "2026-01-08T04:44:19.668126Z",
     "shell.execute_reply": "2026-01-08T04:44:19.666370Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Ensure project root is on sys.path so `src` imports work when running cells\n",
    "p = Path.cwd()\n",
    "for _ in range(6):\n",
    "    if (p / 'src').exists():\n",
    "        sys.path.insert(0, str(p))\n",
    "        break\n",
    "    p = p.parent\n",
    "else:\n",
    "    # fallback: add current working dir\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Reuse preprocessing utilities from src for consistent behavior\n",
    "from src.preprocessing import clean_numeric_columns, parse_dates, save_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cấu hình và Đường dẫn\n",
    "Khai báo đường dẫn đến các file dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:44:19.672630Z",
     "iopub.status.busy": "2026-01-08T04:44:19.672425Z",
     "iopub.status.idle": "2026-01-08T04:44:19.678634Z",
     "shell.execute_reply": "2026-01-08T04:44:19.678225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using raw data directory: /Users/admin/ML/3A_Superstore/data/rawdata\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Enforce canonical raw directory 'data/rawdata' and required filenames\n",
    "p = Path.cwd()\n",
    "base_path = None\n",
    "for _ in range(6):\n",
    "    candidate = p / 'data' / 'rawdata'\n",
    "    if candidate.exists():\n",
    "        base_path = candidate\n",
    "        break\n",
    "    p = p.parent\n",
    "\n",
    "if base_path is None:\n",
    "    raise FileNotFoundError(\"Missing required raw directory 'data/rawdata' (searching upward from notebook). Please place raw files there.\")\n",
    "\n",
    "required_files = ['Orders.csv', 'Order_Details.csv', 'Customers.csv']\n",
    "missing = [f for f in required_files if not (base_path / f).exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"Missing required raw files in {base_path}: {missing}. Please place raw files into 'data/rawdata' with names: {required_files}.\")\n",
    "\n",
    "orders_path = base_path / 'Orders.csv'\n",
    "details_path = base_path / 'Order_Details.csv'\n",
    "customers_path = base_path / 'Customers.csv'\n",
    "\n",
    "print(f\"Using raw data directory: {base_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Đọc dữ liệu\n",
    "Đọc dữ liệu từ file CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:44:19.705406Z",
     "iopub.status.busy": "2026-01-08T04:44:19.705134Z",
     "iopub.status.idle": "2026-01-08T04:44:58.420877Z",
     "shell.execute_reply": "2026-01-08T04:44:58.420342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Orders shape: (10235193, 6)\n",
      "Details shape: (51185032, 7)\n",
      "Customers shape: (99998, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "\n",
    "from src.preprocessing import robust_read_processed\n",
    "\n",
    "# If raw split files exist, read them; otherwise try loading an existing processed file\n",
    "if orders_path.exists() and details_path.exists() and customers_path.exists():\n",
    "    # Robust CSV reader for raw split files\n",
    "    def robust_read_csv(path, **kwargs):\n",
    "        try:\n",
    "            return pd.read_csv(path, **kwargs)\n",
    "        except Exception:\n",
    "            for sep in [';', ',']:\n",
    "                for enc in ['utf-8', 'latin-1']:\n",
    "                    try:\n",
    "                        return pd.read_csv(path, sep=sep, encoding=enc, engine='python')\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            raise\n",
    "\n",
    "    # Load Orders\n",
    "    orders = robust_read_csv(orders_path)\n",
    "    print(f\"Orders shape: {orders.shape}\")\n",
    "\n",
    "    # Load Details\n",
    "    details = robust_read_csv(details_path)\n",
    "    print(f\"Details shape: {details.shape}\")\n",
    "\n",
    "    # Load Customers\n",
    "    customers = robust_read_csv(customers_path)\n",
    "    print(f\"Customers shape: {customers.shape}\")\n",
    "else:\n",
    "    print(\"Raw split files not found. Attempting to load existing processed dataset 'data/processed_data.csv'...\")\n",
    "\n",
    "    # Try to find processed_data.csv by searching upward from current working directory\n",
    "    p = Path.cwd()\n",
    "    processed_path = None\n",
    "    for _ in range(6):\n",
    "        candidate = p / 'data' / 'processed_data.csv'\n",
    "        if candidate.exists():\n",
    "            processed_path = str(candidate)\n",
    "            break\n",
    "        candidate2 = p / 'processed_data.csv'\n",
    "        if candidate2.exists():\n",
    "            processed_path = str(candidate2)\n",
    "            break\n",
    "        p = p.parent\n",
    "\n",
    "    if processed_path is None:\n",
    "        # fallback to default behavior of robust_read_processed which searches local paths\n",
    "        final_df, sep = robust_read_processed()\n",
    "    else:\n",
    "        final_df, sep = robust_read_processed(processed_path)\n",
    "\n",
    "    print(f\"Loaded processed dataset with shape: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lấy mẫu (Sampling)\n",
    "Giảm kích thước dữ liệu để thuận tiện cho việc xử lý và phân tích. Chúng ta lấy mẫu theo Orders ID để đảm bảo tính toàn vẹn của đơn hàng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:44:58.423985Z",
     "iopub.status.busy": "2026-01-08T04:44:58.423876Z",
     "iopub.status.idle": "2026-01-08T04:44:59.130551Z",
     "shell.execute_reply": "2026-01-08T04:44:59.130311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling orders to reduce dataset size...\n",
      "Sampled Orders shape: (12000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sampling orders to reduce dataset size...\")\n",
    "\n",
    "if 'final_df' in globals():\n",
    "    print(\"Processed dataset already loaded; skipping raw-order sampling.\")\n",
    "else:\n",
    "    # If dataset is large, sample orders to keep processing fast for prototyping\n",
    "    TARGET_ORDERS = 12000\n",
    "    if len(orders) > TARGET_ORDERS:\n",
    "        orders = orders.sample(n=TARGET_ORDERS, random_state=42)\n",
    "\n",
    "    print(f\"Sampled Orders shape: {orders.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Làm sạch dữ liệu (Data Cleaning)\n",
    "- Chuyển đổi định dạng tiền tệ (chuỗi có dấu phẩy sang float)\n",
    "- Chuyển đổi định dạng ngày tháng\n",
    "- Lọc dữ liệu chi tiết và khách hàng theo danh sách đơn hàng đã lấy mẫu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:44:59.132101Z",
     "iopub.status.busy": "2026-01-08T04:44:59.132014Z",
     "iopub.status.idle": "2026-01-08T04:45:01.179524Z",
     "shell.execute_reply": "2026-01-08T04:45:01.179204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data using src.preprocessing helpers...\n",
      "Orders: (12000, 6)\n",
      "Details: (59997, 7)\n",
      "Customers: (11329, 11)\n",
      "Orders: (12000, 6)\n",
      "Details: (59997, 7)\n",
      "Customers: (11329, 11)\n",
      "Orders: (12000, 6)\n",
      "Details: (59997, 7)\n",
      "Customers: (11329, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/ML/3A_Superstore/src/preprocessing.py:94: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[col] = pd.to_datetime(df[col], dayfirst=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning data using src.preprocessing helpers...\")\n",
    "\n",
    "from src.preprocessing import clean_numeric_columns, parse_dates\n",
    "\n",
    "if 'final_df' in globals():\n",
    "    # Assume final_df already cleaned in previous run; ensure numeric normalization and date parsing\n",
    "    final_df = clean_numeric_columns(final_df, cols=['TOTALBASKET','UNITPRICE','TOTALPRICE','AMOUNT'])\n",
    "    final_df = parse_dates(final_df, col='DATE_')\n",
    "    final_df = parse_dates(final_df, col='USERBIRTHDATE')\n",
    "    print('Processed dataset cleaned (normalized numeric columns and parsed dates).')\n",
    "else:\n",
    "    # Clean Orders\n",
    "    orders = clean_numeric_columns(orders, cols=['TOTALBASKET'])\n",
    "    orders = parse_dates(orders, col='DATE_')\n",
    "\n",
    "    # Filter and clean Details\n",
    "    details = details[details['ORDERID'].isin(orders['ORDERID'])]\n",
    "    details = clean_numeric_columns(details, cols=['UNITPRICE', 'TOTALPRICE'])\n",
    "\n",
    "    # Filter and parse Customers\n",
    "    customers = customers[customers['USERID'].isin(orders['USERID'])]\n",
    "    customers = parse_dates(customers, col='USERBIRTHDATE')\n",
    "\n",
    "    # Basic validation\n",
    "required_columns = {\n",
    "    'orders': ['ORDERID', 'USERID'],\n",
    "    'details': ['ORDERID'],\n",
    "    'customers': ['USERID']\n",
    "}\n",
    "\n",
    "for dfname, df in [('orders', orders), ('details', details), ('customers', customers)]:\n",
    "    for col in required_columns[dfname]:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Required column {col} missing in {dfname} dataframe\")\n",
    "\n",
    "    # Show concise summaries\n",
    "    print('Orders:', orders.shape)\n",
    "    print('Details:', details.shape)\n",
    "    print('Customers:', customers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hợp nhất dữ liệu (Merging)\n",
    "Kết nối 3 bảng Orders, Order Details, và Customers lại thành một bảng duy nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:45:01.180832Z",
     "iopub.status.busy": "2026-01-08T04:45:01.180750Z",
     "iopub.status.idle": "2026-01-08T04:45:01.212354Z",
     "shell.execute_reply": "2026-01-08T04:45:01.212055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging data...\n",
      "Dropping overlapping columns from customers before merge: ['NAMESURNAME']\n",
      "Merged shape: (59997, 21)\n",
      "Merged and limited (if applicable): (59997, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging data...\")\n",
    "\n",
    "if 'final_df' in globals():\n",
    "    print(f\"Skipping merge, using existing processed data with shape: {final_df.shape}\")\n",
    "else:\n",
    "    # Merge Orders with Details on ORDERID\n",
    "    merged_orders = pd.merge(details, orders, on='ORDERID', how='left')\n",
    "    \n",
    "    # Merge with Customers on USERID\n",
    "    # Drop overlapping columns from customers to avoid _x, _y suffixes (e.g. NAMESURNAME)\n",
    "    customers_to_merge = customers.copy()\n",
    "    overlap_cols = [c for c in customers_to_merge.columns if c in merged_orders.columns and c != 'USERID']\n",
    "    if overlap_cols:\n",
    "        print(f\"Dropping overlapping columns from customers before merge: {overlap_cols}\")\n",
    "        customers_to_merge = customers_to_merge.drop(columns=overlap_cols)\n",
    "        \n",
    "    final_df = pd.merge(merged_orders, customers_to_merge, on='USERID', how='left')\n",
    "\n",
    "    print(f\"Merged shape: {final_df.shape}\")\n",
    "\n",
    "    # If extremely large (unlikely after sampling), downsample for prototyping\n",
    "    if len(final_df) > 1000000:\n",
    "        final_df = final_df.sample(n=1000000, random_state=42)\n",
    "\n",
    "    print('Merged and limited (if applicable):', final_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering\n",
    "Tạo các đặc trưng mới:\n",
    "- **Year, Month**: Từ ngày đặt hàng\n",
    "- **Age**: Tuổi của khách hàng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:45:01.213725Z",
     "iopub.status.busy": "2026-01-08T04:45:01.213645Z",
     "iopub.status.idle": "2026-01-08T04:45:01.375023Z",
     "shell.execute_reply": "2026-01-08T04:45:01.374733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns now include: ['Year', 'Month', 'Age']\n",
      "Sample rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  Age\n",
       "0     NaN    NaN   69\n",
       "1     NaN    NaN   73\n",
       "2  2021.0    1.0   35\n",
       "3     NaN    NaN   30\n",
       "4     NaN    NaN   33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure DATE_ is datetime and create time features\n",
    "final_df['Year'] = final_df['DATE_'].dt.year\n",
    "final_df['Month'] = final_df['DATE_'].dt.month\n",
    "\n",
    "# Calculate Age from USERBIRTHDATE if available\n",
    "def compute_age(birthdate):\n",
    "    if pd.isna(birthdate):\n",
    "        return pd.NA\n",
    "    try:\n",
    "        return pd.Timestamp.now().year - birthdate.year\n",
    "    except Exception:\n",
    "        return pd.NA\n",
    "\n",
    "final_df['Age'] = final_df['USERBIRTHDATE'].apply(compute_age)\n",
    "\n",
    "# Quick check\n",
    "print('Columns now include:', ['Year','Month','Age'])\n",
    "print('Sample rows:')\n",
    "final_df[['Year','Month','Age']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lưu và Kiểm tra kết quả\n",
    "Lưu dữ liệu đã xử lý ra file CSV mới và hiển thị thông tin mẫu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:45:01.377061Z",
     "iopub.status.busy": "2026-01-08T04:45:01.376923Z",
     "iopub.status.idle": "2026-01-08T04:45:02.270469Z",
     "shell.execute_reply": "2026-01-08T04:45:02.270121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to data/processed_data.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59997 entries, 0 to 59996\n",
      "Data columns (total 24 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   ORDERID        59997 non-null  int64         \n",
      " 1   ORDERDETAILID  59997 non-null  int64         \n",
      " 2   AMOUNT         59997 non-null  int64         \n",
      " 3   UNITPRICE      59997 non-null  float64       \n",
      " 4   TOTALPRICE     59997 non-null  float64       \n",
      " 5   ITEMID         59997 non-null  int64         \n",
      " 6   ITEMCODE       59997 non-null  int64         \n",
      " 7   BRANCH_ID      59997 non-null  object        \n",
      " 8   DATE_          23866 non-null  datetime64[ns]\n",
      " 9   USERID         59997 non-null  int64         \n",
      " 10  NAMESURNAME    59997 non-null  object        \n",
      " 11  TOTALBASKET    59997 non-null  float64       \n",
      " 12  USERNAME_      59997 non-null  object        \n",
      " 13  STATUS_        59997 non-null  int64         \n",
      " 14  USERGENDER     59997 non-null  object        \n",
      " 15  USERBIRTHDATE  59997 non-null  datetime64[ns]\n",
      " 16  REGION         59997 non-null  object        \n",
      " 17  CITY           59997 non-null  object        \n",
      " 18  TOWN           59997 non-null  object        \n",
      " 19  DISTRICT       59997 non-null  object        \n",
      " 20  ADDRESSTEXT    59997 non-null  object        \n",
      " 21  Year           23866 non-null  float64       \n",
      " 22  Month          23866 non-null  float64       \n",
      " 23  Age            59997 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(5), int64(8), object(9)\n",
      "memory usage: 11.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDERID</th>\n",
       "      <th>ORDERDETAILID</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>UNITPRICE</th>\n",
       "      <th>TOTALPRICE</th>\n",
       "      <th>ITEMID</th>\n",
       "      <th>ITEMCODE</th>\n",
       "      <th>BRANCH_ID</th>\n",
       "      <th>DATE_</th>\n",
       "      <th>USERID</th>\n",
       "      <th>...</th>\n",
       "      <th>USERGENDER</th>\n",
       "      <th>USERBIRTHDATE</th>\n",
       "      <th>REGION</th>\n",
       "      <th>CITY</th>\n",
       "      <th>TOWN</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>ADDRESSTEXT</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4316432</td>\n",
       "      <td>21584356</td>\n",
       "      <td>5</td>\n",
       "      <td>59.40</td>\n",
       "      <td>176.15</td>\n",
       "      <td>15973</td>\n",
       "      <td>27425</td>\n",
       "      <td>56-AN1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>30892</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1957-09-07</td>\n",
       "      <td>Ic Anadolu</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>CANKAYA</td>\n",
       "      <td>MUTLUKENT MAH.</td>\n",
       "      <td>MUTLUKENT MAH. 1986. SOKAK  06800  CANKAYA/ANKARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6788624</td>\n",
       "      <td>33953557</td>\n",
       "      <td>1</td>\n",
       "      <td>34.55</td>\n",
       "      <td>26.01</td>\n",
       "      <td>15934</td>\n",
       "      <td>27386</td>\n",
       "      <td>56-AN1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>71967</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1953-07-03</td>\n",
       "      <td>Ic Anadolu</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>CANKAYA</td>\n",
       "      <td>KIRKKONAKLAR MAH.</td>\n",
       "      <td>KIRKKONAKLAR MAH. 361. SOKAK  06610  CANKAYA/A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3377453</td>\n",
       "      <td>16887270</td>\n",
       "      <td>2</td>\n",
       "      <td>59.50</td>\n",
       "      <td>76.32</td>\n",
       "      <td>17678</td>\n",
       "      <td>28033</td>\n",
       "      <td>56-AN4</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>55698</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1991-02-13</td>\n",
       "      <td>Ic Anadolu</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>KECIOREN</td>\n",
       "      <td>GUCLUKAYA MAH.</td>\n",
       "      <td>GUCLUKAYA MAH. KEREM SOKAK  06310  KECIOREN/AN...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6141661</td>\n",
       "      <td>30714643</td>\n",
       "      <td>8</td>\n",
       "      <td>32.45</td>\n",
       "      <td>242.40</td>\n",
       "      <td>7449</td>\n",
       "      <td>22972</td>\n",
       "      <td>56-AN1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>19596</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1996-11-12</td>\n",
       "      <td>Ic Anadolu</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>MAMAK</td>\n",
       "      <td>EGE MAH.</td>\n",
       "      <td>EGE MAH. 758. SOKAK  06480  MAMAK/ANKARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3519105</td>\n",
       "      <td>17594071</td>\n",
       "      <td>7</td>\n",
       "      <td>64.50</td>\n",
       "      <td>392.70</td>\n",
       "      <td>22967</td>\n",
       "      <td>44770</td>\n",
       "      <td>56-AN4</td>\n",
       "      <td>NaT</td>\n",
       "      <td>37719</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1993-09-04</td>\n",
       "      <td>Ic Anadolu</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>ETIMESGUT</td>\n",
       "      <td>BAGLICA MAH.</td>\n",
       "      <td>BAGLICA MAH. 1000. SOKAK  06790  ETIMESGUT/ANKARA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ORDERID  ORDERDETAILID  AMOUNT  UNITPRICE  TOTALPRICE  ITEMID  ITEMCODE  \\\n",
       "0  4316432       21584356       5      59.40      176.15   15973     27425   \n",
       "1  6788624       33953557       1      34.55       26.01   15934     27386   \n",
       "2  3377453       16887270       2      59.50       76.32   17678     28033   \n",
       "3  6141661       30714643       8      32.45      242.40    7449     22972   \n",
       "4  3519105       17594071       7      64.50      392.70   22967     44770   \n",
       "\n",
       "  BRANCH_ID      DATE_  USERID  ... USERGENDER  USERBIRTHDATE      REGION  \\\n",
       "0    56-AN1        NaT   30892  ...          M     1957-09-07  Ic Anadolu   \n",
       "1    56-AN1        NaT   71967  ...          M     1953-07-03  Ic Anadolu   \n",
       "2    56-AN4 2021-01-04   55698  ...          F     1991-02-13  Ic Anadolu   \n",
       "3    56-AN1        NaT   19596  ...          F     1996-11-12  Ic Anadolu   \n",
       "4    56-AN4        NaT   37719  ...          F     1993-09-04  Ic Anadolu   \n",
       "\n",
       "     CITY       TOWN           DISTRICT  \\\n",
       "0  Ankara    CANKAYA     MUTLUKENT MAH.   \n",
       "1  Ankara    CANKAYA  KIRKKONAKLAR MAH.   \n",
       "2  Ankara   KECIOREN     GUCLUKAYA MAH.   \n",
       "3  Ankara      MAMAK           EGE MAH.   \n",
       "4  Ankara  ETIMESGUT       BAGLICA MAH.   \n",
       "\n",
       "                                         ADDRESSTEXT    Year Month Age  \n",
       "0  MUTLUKENT MAH. 1986. SOKAK  06800  CANKAYA/ANKARA     NaN   NaN  69  \n",
       "1  KIRKKONAKLAR MAH. 361. SOKAK  06610  CANKAYA/A...     NaN   NaN  73  \n",
       "2  GUCLUKAYA MAH. KEREM SOKAK  06310  KECIOREN/AN...  2021.0   1.0  35  \n",
       "3           EGE MAH. 758. SOKAK  06480  MAMAK/ANKARA     NaN   NaN  30  \n",
       "4  BAGLICA MAH. 1000. SOKAK  06790  ETIMESGUT/ANKARA     NaN   NaN  33  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove username/surname related columns before saving\n",
    "cols_to_drop = [c for c in final_df.columns if 'USERNAME' in c.upper() or 'SURNAME' in c.upper()]\n",
    "if cols_to_drop:\n",
    "    final_df = final_df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "# Save processed data using utility to ensure consistent path/dirs\n",
    "output_path = Path('data') / 'processed_data.csv'\n",
    "save_processed(final_df, out=str(output_path))\n",
    "print(f\"Saved processed data to {output_path}\")\n",
    "\n",
    "# Quick inspection\n",
    "print(final_df.info())\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:45:02.271769Z",
     "iopub.status.busy": "2026-01-08T04:45:02.271668Z",
     "iopub.status.idle": "2026-01-08T04:45:03.141290Z",
     "shell.execute_reply": "2026-01-08T04:45:03.140933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-saved processed_data.csv using save_processed\n"
     ]
    }
   ],
   "source": [
    "# Re-save processed data using safe save (sanitize + explicit sep/encoding)\n",
    "import importlib\n",
    "import src.preprocessing as sp\n",
    "importlib.reload(sp)\n",
    "sp.save_processed(final_df, out='data/processed_data.csv', sep=';')\n",
    "print('Re-saved processed_data.csv using save_processed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
